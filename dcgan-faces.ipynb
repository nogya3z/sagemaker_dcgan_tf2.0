{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN TF 2.0 on Sagemaker\n",
    "### There are many Tensorflow Tutorials, and there are many guides on how to use Sagemaker.\n",
    "### However, there are very few guides on how to implement Tensorflow 2.0 in Sagemaker!\n",
    "This notebook is meant to help those trying to implement their Tensorflow 2.0 neural nets in Sagemaker.\n",
    "\n",
    "https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/tensorflow_bring_your_own/tensorflow_bring_your_own.ipynb\n",
    "\n",
    "The above link from AWS gives a thorough guide on how to deploy one's custom algorithm. The code in the link served as a rough guideline when making the code associated with this project. However, many changes were made. \n",
    "\n",
    "First, I utilized a DCGAN with Tensorflow 2.0. AWS Sagemaker utilizes docker for deploying and training neural networks. For convenience, AWS has official docker images to deploy Tensorflow algorithms, however, the most recent release is compatible with Tensorflow version 1.14.0. This means that I had to find another image and get all the relevant dependencies.\n",
    "\n",
    "The image used is tensorflow/tensorflow:nightly-custom-op-gpu-ubuntu16-cuda10.0.\n",
    "Perhaps there is a better one out there, but this one seemed to work best. \n",
    "\n",
    "As far as the DCGAN used, Tensorflow provides a very good starting point below:\n",
    "\n",
    "https://www.tensorflow.org/tutorials/generative/dcgan\n",
    "\n",
    "\n",
    "However, as I decided that I wanted to train my network on the celebA dataset, and not on MNIST, I needed a larger neural network to do the job. I decided to use the network structure from the following tutorial:\n",
    "\n",
    "https://github.com/skywall34/BabyGan/blob/master/DCGAN_CelebA.ipynb\n",
    "\n",
    "\n",
    "The image set has about 200,000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import imageio\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import sagemaker as sage\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from data_pipeline import download_unzip_upload\n",
    "from IPython import display\n",
    "from sagemaker.estimator import Estimator \n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "sess = sage.Session()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Preprocessing\n",
    "\n",
    "### celebA image set\n",
    "This is one of the more common image sets used. You can use other datasets as well like cifar or from your own collection. Below is code used to automatically download the celebA dataset:\n",
    "\n",
    "https://gist.github.com/charlesreid1/4f3d676b33b95fce83af08e4ec261822\n",
    "\n",
    "In addition to this, we unzip, resize [64x64], and finally combine them all into a single tfrecord, uploading it into s3.\n",
    "\n",
    "### Important:\n",
    "The tfrecord conversion is compatible with tensorflow 2.0 or higher. I haven't found a simple way to upgrade Sagemaker instances themselves to Tensorflow 2.0. So the data processing should be run either outside the notebook instance (ie. on your local machine), or in an isolated environment (ie. a docker container)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"[BUCKET_NAME]\"\n",
    "#enter the name of your AWS bucket\n",
    "file_id = '0B7EVK8r0v71pZjFTYXZWM3FlRnM'\n",
    "#this is the name of the id for the celebA zip file.\n",
    "destination = \"celebA.zip\"\n",
    "#we  download the celebA zip file as celebA.zip or whatever name you prefer\n",
    "output_file = \"train.tfrecords\"\n",
    "#output the file in tf record format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_records = download_unzip_upload(file_id, destination, output_file, bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prepare_records.run_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and pushing out Docker Image\n",
    "\n",
    "### Below we read from our Dockerfile.\n",
    "\n",
    "For more information please refer to:\n",
    "\n",
    "https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/tensorflow_bring_your_own/tensorflow_bring_your_own.ipynb\n",
    "\n",
    "Or:\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/amazon-sagemaker-containers.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat container/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code conveniently pushes our docker image to ECR where it can be called when we actually run our algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=dcgan-dogs\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x train\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-east-1 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running our neural network\n",
    "\n",
    "### Here we define the last variables and parameters needed before we can finally run our DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locations where we get our data, and where we output our model and images\n",
    "data_key1 = 'work_folder/output'\n",
    "data_key2 = 'work_folder/train.tfrecords'\n",
    "output_location = 's3://{}/{}'.format(bucket_name, data_key1)\n",
    "data_location = 's3://{}/{}'.format(bucket_name, data_key2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/dcgan-dogs:latest'.format(account, region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'epochs': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we choose a ml.p2.xlarge instance. This is the cheapest GPU instance available for training on Sagemaker.  \n",
    "\n",
    "Training on this instance will incur charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "estimator = Estimator(image_name= image,\n",
    "              hyperparameters = hyperparameters,\n",
    "              role= role,\n",
    "              output_path=output_location,\n",
    "              train_instance_count=1,\n",
    "              train_instance_type='ml.p2.xlarge')\n",
    "              #train_instance_type='local')\n",
    "    \n",
    "    \n",
    "estimator.fit(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, let's look in our output_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in bucket.objects.filter(Prefix=data_key1):\n",
    "    key = obj.key\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy the recently added file, and then paste below to untar.\n",
    "#note that the tmp folder clear on restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3a = boto3.client('s3')\n",
    "s3a.download_file(bucket_name, 'path/to/model/output/model.tar.gz', '/tmp/results.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = tarfile.open(\"/tmp/results.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar.extractall(path=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_file = 'dcgan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob('output/images/000image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  last = -1\n",
    "  for i,filename in enumerate(filenames):\n",
    "    frame = 2*(i**0.5)\n",
    "    if round(frame) > round(last):\n",
    "      last = frame\n",
    "    else:\n",
    "      continue\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "display.Image(filename=anim_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Thoughts:\n",
    "\n",
    "### Training actually seemed quicker when run on google Colab\n",
    "I'd recommend, with this network, to just run it on google Colab. Most of the code would be the same, and you will not incur any extra costs.\n",
    "\n",
    "### So why bother on Sagemaker?\n",
    "Google Colab or a local machine are perfectly fine options for training models. However, when our datasets begin to become too large or we just want to get our results much faster, the cloud is where we go. AWS is great because of scalability. S3 offers a large datastore. We can also scale up our gpu power by using more powerful instances. However, this does require that we modify the provided code to accomodate multi-gpu utilizaton.\n",
    "\n",
    "### Final Takeaway:\n",
    "This code is great for simultaneously learning about one of the most exciting neural networks around, DCGAN's, as well as becoming more familiar with deploying custom algorithms in the cloud. The next iteration of this project will be running this same code but on multiple GPU's, as it doesn't make any sense to pay for a GPU when you can already use one locally or even on Colab for a comparable ammount of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}